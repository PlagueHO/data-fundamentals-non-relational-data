{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - Azure Data Lake Storage Gen2\n",
    "\n",
    "In this task, we will look at how to create an Azure Data Lake Storage account and upload a file to it. Azure Data Lake Storage Gen2 is a set of capabilities dedicated to big data analytics, built on Azure Blob storage. Azure Data Lake Storage Gen2 is the result of converging the capabilities of Azure Data Lake Storage Gen1 with Azure Blob storage.\n",
    "\n",
    "Creating an Azure Data Lake Storage gen2 account is the same as creating an Azure Storage account, but we select he Hierarchical namespace as the storage account kind.\n",
    "\n",
    " Open the Azure portal.\n",
    "1. Search for `Storage accounts` and click on it.\n",
    "1. Click on the `+ Create` button to create a new storage account.\n",
    "1. Fill in the basic details to create a new storage account.\n",
    "\n",
    "   > Important: Storage Account names must be globally unique. You may need to try a few different names before you find one that is available.\n",
    "\n",
    "   ![Basics](../images/02-azure-data-lake-storage-gen2-basics.png)\n",
    "\n",
    "1. Click `Next`.\n",
    "1. Tick `Enable hierarchical namespace`.\n",
    "\n",
    "   ![Advanced](../images/02-azure-data-lake-storage-gen2-advanced.png)\n",
    "   \n",
    "1. Click `Review + Create`.\n",
    "1. Click `Create`.\n",
    "1. After the storage account is created, navigate to it in the Portal.\n",
    "1. Select `Containers` blade under `Data Storage`.\n",
    "1. Click `+ Container` to create a new container and name it `postanalytics`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an analytics data structure to Azure Data Lake Storage Gen2 using Python\n",
    "\n",
    "In this task, we will create an analytics structure (a folder for each date in a month) in Azure Data Lake Storage Gen2 and upload some files to it.\n",
    "\n",
    "You'll need to get the Storage Account key from the Azure Portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-storage-file-datalake\n",
      "  Using cached azure_storage_file_datalake-12.15.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: azure-core>=1.28.0 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-storage-file-datalake) (1.30.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.20.0 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-storage-file-datalake) (12.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-storage-file-datalake) (4.9.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-storage-file-datalake) (0.6.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-core>=1.28.0->azure-storage-file-datalake) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-core>=1.28.0->azure-storage-file-datalake) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from azure-storage-blob>=12.20.0->azure-storage-file-datalake) (42.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.20.0->azure-storage-file-datalake) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-file-datalake) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-file-datalake) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-file-datalake) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.28.0->azure-storage-file-datalake) (2024.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dascottr\\appdata\\local\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.20.0->azure-storage-file-datalake) (2.21)\n",
      "Using cached azure_storage_file_datalake-12.15.0-py3-none-any.whl (254 kB)\n",
      "Installing collected packages: azure-storage-file-datalake\n",
      "Successfully installed azure-storage-file-datalake-12.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment next line if not running in Devcontainer\n",
    "# %pip install azure-storage-file-datalake, pandas, numpy\n",
    "\n",
    "# Configure these for your Azure Storage Account\n",
    "account_name = '<your storage account name>'\n",
    "account_key = '<your storage account key>'\n",
    "\n",
    "# Define the container name\n",
    "container_name = 'postanalytics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder: 2024-06-01\n",
      "Created folder: 2024-06-02\n",
      "Created folder: 2024-06-03\n",
      "Created folder: 2024-06-04\n",
      "Created folder: 2024-06-05\n",
      "Created folder: 2024-06-06\n",
      "Created folder: 2024-06-07\n",
      "Created folder: 2024-06-08\n",
      "Created folder: 2024-06-09\n",
      "Created folder: 2024-06-10\n",
      "Created folder: 2024-06-11\n",
      "Created folder: 2024-06-12\n",
      "Created folder: 2024-06-13\n",
      "Created folder: 2024-06-14\n",
      "Created folder: 2024-06-15\n",
      "Created folder: 2024-06-16\n",
      "Created folder: 2024-06-17\n",
      "Created folder: 2024-06-18\n",
      "Created folder: 2024-06-19\n",
      "Created folder: 2024-06-20\n",
      "Created folder: 2024-06-21\n",
      "Created folder: 2024-06-22\n",
      "Created folder: 2024-06-23\n",
      "Created folder: 2024-06-24\n",
      "Created folder: 2024-06-25\n",
      "Created folder: 2024-06-26\n",
      "Created folder: 2024-06-27\n",
      "Created folder: 2024-06-28\n",
      "Created folder: 2024-06-29\n",
      "Created folder: 2024-06-30\n"
     ]
    }
   ],
   "source": [
    "# Create an analytics folder structure in Azure Data Lake Storage gen2 with one date folder per day\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Create a DataLakeServiceClient\n",
    "datalake_service_client = DataLakeServiceClient(account_url=\"{}://{}.dfs.core.windows.net\".format(\n",
    "    \"https\", account_name), credential=account_key)\n",
    "\n",
    "# Create a file system\n",
    "file_system_client = datalake_service_client.get_file_system_client(file_system=container_name)\n",
    "\n",
    "# Create a date folder for each day in the previous month\n",
    "today = datetime.date.today()\n",
    "first_day_of_month = today.replace(day=1)\n",
    "last_day_of_previous_month = first_day_of_month - datetime.timedelta(days=1)\n",
    "\n",
    "for day in range(1, last_day_of_previous_month.day + 1):\n",
    "    date_folder = last_day_of_previous_month.replace(day=day).strftime('%Y-%m-%d')\n",
    "    directory_client = file_system_client.get_directory_client(date_folder)\n",
    "    directory_client.create_directory()\n",
    "\n",
    "    print(f\"Created folder: {date_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created files in folder: 2024-06-01\n",
      "Created files in folder: 2024-06-02\n",
      "Created files in folder: 2024-06-03\n",
      "Created files in folder: 2024-06-04\n",
      "Created files in folder: 2024-06-05\n",
      "Created files in folder: 2024-06-06\n",
      "Created files in folder: 2024-06-07\n",
      "Created files in folder: 2024-06-08\n",
      "Created files in folder: 2024-06-09\n",
      "Created files in folder: 2024-06-10\n",
      "Created files in folder: 2024-06-11\n",
      "Created files in folder: 2024-06-12\n",
      "Created files in folder: 2024-06-13\n",
      "Created files in folder: 2024-06-14\n",
      "Created files in folder: 2024-06-15\n",
      "Created files in folder: 2024-06-16\n",
      "Created files in folder: 2024-06-17\n",
      "Created files in folder: 2024-06-18\n",
      "Created files in folder: 2024-06-19\n",
      "Created files in folder: 2024-06-20\n",
      "Created files in folder: 2024-06-21\n",
      "Created files in folder: 2024-06-22\n",
      "Created files in folder: 2024-06-23\n",
      "Created files in folder: 2024-06-24\n",
      "Created files in folder: 2024-06-25\n",
      "Created files in folder: 2024-06-26\n",
      "Created files in folder: 2024-06-27\n",
      "Created files in folder: 2024-06-28\n",
      "Created files in folder: 2024-06-29\n",
      "Created files in folder: 2024-06-30\n"
     ]
    }
   ],
   "source": [
    "# For each day in the previous month, create a postanalytics.csv and commentsanalytics.csv file in Azure Data Lake Storage gen2 container that contains randomly generated content\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for day in range(1, last_day_of_previous_month.day + 1):\n",
    "    date_folder = last_day_of_previous_month.replace(day=day).strftime('%Y-%m-%d')\n",
    "    directory_client = file_system_client.get_directory_client(date_folder)\n",
    "\n",
    "    # Create a postanalytics.csv file\n",
    "    postanalytics_file_client = directory_client.get_file_client(\"postanalytics.csv\")\n",
    "    postanalytics_data = pd.DataFrame({\n",
    "        'PostId': np.random.randint(1, 1000, 1000),\n",
    "        'PostTitle': np.random.choice(['Azure', 'Data', 'AI', 'Machine Learning', 'Python'], 1000),\n",
    "        'PostViews': np.random.randint(1, 1000, 1000),\n",
    "        'PostLikes': np.random.randint(1, 100, 1000),\n",
    "        'PostComments': np.random.randint(1, 50, 1000)\n",
    "    })\n",
    "    postanalytics_file_client.create_file()\n",
    "    postanalytics_file_client.append_data(data=postanalytics_data.to_csv(index=False), offset=0, length=len(postanalytics_data.to_csv(index=False)))\n",
    "    postanalytics_file_client.flush_data(len(postanalytics_data.to_csv(index=False)))\n",
    "\n",
    "    # Create a commentsanalytics.csv file\n",
    "    commentsanalytics_file_client = directory_client.get_file_client(\"commentsanalytics.csv\")\n",
    "    commentsanalytics_data = pd.DataFrame({\n",
    "        'CommentId': np.random.randint(1, 1000, 1000),\n",
    "        'PostId': np.random.randint(1, 1000, 1000),\n",
    "        'CommentText': np.random.choice(['Great post!', 'Thanks for sharing', 'I agree', 'Interesting', 'Not helpful'], 1000),\n",
    "        'CommentLikes': np.random.randint(1, 50, 1000)\n",
    "    })\n",
    "    commentsanalytics_file_client.create_file()\n",
    "    commentsanalytics_file_client.append_data(data=commentsanalytics_data.to_csv(index=False), offset=0, length=len(commentsanalytics_data.to_csv(index=False)))\n",
    "    commentsanalytics_file_client.flush_data(len(commentsanalytics_data.to_csv(index=False)))\n",
    "\n",
    "    print(f\"Created files in folder: {date_folder}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
